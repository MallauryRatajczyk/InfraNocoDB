provider "google" {
  project = var.gcp_project
  region  = var.gcp_region
}

resource "google_compute_address" "static_ip_nocodb" { #Cr√©er une IP Statique
  name   = "static-ip-nocodb"
  region = var.gcp_region
}

# üîπ Supprime l'ancienne cl√© SSH pour √©viter l'erreur `WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!`
resource "null_resource" "clear_ssh_known_hosts" {
  provisioner "local-exec" {
    command = "ssh-keygen -f ~/.ssh/known_hosts -R ${google_compute_address.static_ip_nocodb.address}"
  }

  triggers = {
    always_run = "${timestamp()}" # Force l'ex√©cution √† chaque `terraform apply`
  }
}

resource "google_compute_instance" "nocodb-instance" { #Cr√©ation d'une VM pour h√©berger NocoDB
  name         = "nocodb-instance"
  hostname     = var.hostname
  machine_type = var.ci_runner_instance_type
  project      = var.gcp_project
  zone         = var.gcp_zone
  tags         = ["node-exporter", "custom-port"] #Les tags pour le r√©seau

  metadata = {
    # Utilisation d'une cl√© SSH persistante (au lieu d'en g√©n√©rer une √† chaque `terraform apply`)
    ssh-keys = "${var.ansible_user}:${file("${var.ssh_key_file}.pub")}"
  }

  boot_disk { #C'est de ce disque que la VM d√©marre
    initialize_params {
      image = "debian-cloud/debian-12-bookworm-v20250212"
      size  = 20
      type  = "pd-standard"
    } # On peut ajouter d'autres disques pour stocker les donn√©es
  }

  network_interface {
    network = "default"
    access_config {
      // Si vide, IP al√©atoire mais cr√©e automatiquement
      nat_ip = google_compute_address.static_ip_nocodb.address #Utilise l'IP statique d√©finit plus haut
    }
  }

  /* scheduling {
      preemptible       = true
      automatic_restart = false
    }*/ #Permet si activ√© de fermer automatiquement la VM si les ressources sont demand√©es ailleurs et de ne pas red√©marrer automatiquement
}

# resource "google_compute_firewall" "allow_reverse_proxy" { #Configuration du firewall
#   name    = "allow-reverse-proxy"
#   network = "default"

#   allow {
#     protocol = "tcp"
#     ports    = ["32222", "5432", "9100"]
#   }
#   source_ranges = ["34.155.139.235/32", "0.0.0.0/0"] # Seul le reverse proxy peut y acc√©der
# }
resource "google_compute_firewall" "allow_node_exporter" {
  name    = "allow-node-exporter"
  network = "default"

  allow {
    protocol = "tcp"
    ports    = ["9100"]
  }

  source_ranges = ["34.163.103.61/32"]
  target_tags   = ["node-exporter"]
}

resource "google_compute_firewall" "allow_custom_port" {
  name    = "allow-custom-port"
  network = "default"

  allow {
    protocol = "tcp"
    ports    = ["32222"]
  }

  source_ranges = ["34.155.139.235/32"]
  target_tags   = ["custom-port"]
}

output "instance_ip" {
  value       = google_compute_address.static_ip_nocodb.address
  description = "Adresse IP publique de la VM"
}

resource "local_file" "ansible_inventory" { # Cr√©ation du fichier d'inventaire pour Ansible
  content  = <<EOT
[servers]
nocodb-instance ansible_host=${google_compute_address.static_ip_nocodb.address}

[all:vars]
ansible_user=engineer
ansible_ssh_private_key_file=${var.ssh_key_file}
ansible_ssh_common_args='-o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null'
EOT
  filename = "Ansible/inventory.ini"
}
